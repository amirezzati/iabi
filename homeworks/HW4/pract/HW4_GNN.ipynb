{"cells":[{"cell_type":"markdown","metadata":{"id":"U-NtwM1g5JgN"},"source":["# HW4 - Graph Neural Networks\n","\n","## Course Name: Analysis of Medical Images\n","#### Lecturers: Dr. Rohban\n","#### Name: \n","#### Student ID: \n","\n","---\n","\n","**Contact**: Ask your questions in Quera\n","\n","---\n","\n","### Instructions:\n","- Complete all exercises presented in this notebook.\n","- Ensure you run each cell after you've entered your solution.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8g2nm0K58bSk"},"source":["# Introduction\n","\n","This notebook is designed to introduce you to the basics of Graph Neural Networks (GNNs) using a dataset of pathology images. The steps you will follow are:\n","\n","- Download the Dataset: Access and download a set of pathology images.\n","- Data Preprocessing: Prepare the data for processing.\n","- Nuclei Extraction: Identify the location and dimensions of nuclei in the images.\n","- GNN Model Implementation: Develop a GNN for classification.\n","- Experiments: Conduct experiments to test the effectiveness of your model.\n","\n","You are encouraged to use relevant libraries, but please provide brief explanations for your choices and describe how they work."]},{"cell_type":"markdown","metadata":{"id":"-ffExbMs8tbT"},"source":["## Requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700808728074,"user":{"displayName":"Alireza GhahramaniKure","userId":"00756935425877836284"},"user_tz":480},"id":"3bhjyJaF5Crv"},"outputs":[],"source":["!pip install histomicstk --find-links https://girder.github.io/large_image_wheels\n","!pip install ogb\n","!pip install gdown\n","!pip install torchvision\n","!pip install torch_geometric"]},{"cell_type":"markdown","metadata":{"id":"5AtSUFHU9DHn"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTAXHCVD9CQM"},"outputs":[],"source":["import histomicstk as htk  # HistomicsTK for pathology image analysis\n","import numpy as np\n","import scipy as sp\n","import skimage.io\n","import skimage.measure\n","import skimage.color\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import pandas as pd\n","import torch.nn as nn\n","\n","import copy\n","\n","from torchvision.models import resnet18, ResNet18_Weights\n","from sklearn.metrics.pairwise import pairwise_distances\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"6Xbor5g_95JM"},"source":["## Dataset\n","\n","We will use the BRACS test dataset, a collection of Hematoxylin and Eosin (H&E) stained histopathological images for breast tumor classification. The dataset includes over 4,000 tumor regions-of-interest labeled in 7 categories. You can download it using the following commands. Alternatively, you may use any suitable dataset, but ensure it is accessible during evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBg3ynfJ9yRg"},"outputs":[],"source":["!gdown \"https://drive.google.com/uc?export=download&id=1Hk7rtmyR65y4ZXUt9fNN_qlv-A8JyJVd\" -O data.zip\n","!unzip data.zip\n","!rm -rf data.zip"]},{"cell_type":"markdown","metadata":{"id":"Uzddgj61__Dc"},"source":["## Preprocessing and Graphic Model Extraction (15 points)\n","\n","In this section, you will preprocess the images to facilitate model training. Then, identify the position and dimensions of cells using either classic methods or neural networks. Finally, use a neural network (e.g., ResNet18) to embed cell information for node embedding in the GNN.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EQn8gP9BXLS"},"outputs":[],"source":["def images_preprocess(images):\n","    # Add your preprocessing steps here\n","    pass\n","\n","def nuclei_extracting(images):\n","    # Implement nuclei extraction here\n","    pass\n"]},{"cell_type":"markdown","metadata":{"id":"WIIAQKIECfGw"},"source":["## Visualization (3 points)\n","\n","Visualize the results to check accuracy and quality. For example, display a random pathology image alongside the graph of adjacent nuclei.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhdYuf5NCZmV"},"outputs":[],"source":["# Visualization code here"]},{"cell_type":"markdown","metadata":{"id":"af85O_q_ENRk"},"source":["## Dataset Object\n","\n","Create a dataset class suitable for your data. You may use geometric_Dataset, Dataset, or any other method. Please explain your implementation logic if you choose an alternative approach."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jVHD4HQEgZJ"},"outputs":[],"source":["import torch\n","\n","from torch.utils.data import Dataset\n","from torch_geometric.data import Dataset as geometric_Dataset\n","from torch_geometric.data import Data\n","\n","\n","class PathologyDataset(Dataset):\n","    def __init__(self, directory):\n","        pass\n","\n","    def __len__(self):\n","        pass\n","\n","    def __getitem__(self, idx):\n","        pass\n","\n","    def get_idx_split(self):\n","\n","        train_indices = None\n","        test_indices = None\n","        val_indices = None\n","\n","        return {'train': train_indices, 'val': val_indices, 'test': test_indices}"]},{"cell_type":"markdown","metadata":{"id":"PSnItc1hGqjx"},"source":["## GCN Model Implementation (25 points)\n","\n","Implement the GCN model as per the provided architecture. Ensure each step is well-documented. [Please follow the figure below to implement your `forward` function.]\n","\n","![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZmdxSnHGq-F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch_geometric.nn import GCNConv\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n","                 dropout, return_embeds=False):\n","        # TODO: Implement a function that initializes self.convs,\n","        # self.bns, and self.softmax.\n","\n","        super(GCN, self).__init__()\n","\n","        # A list of GCNConv layers\n","        self.convs = None\n","\n","        # A list of 1D batch normalization layers\n","        self.bns = None\n","\n","        # The log softmax layer\n","        self.softmax = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n","        ## 2. self.convs has num_layers GCNConv layers\n","        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n","        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n","        ## 5. The parameters you can set for GCNConv include 'in_channels' and\n","        ## 'out_channels'. For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n","        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n","\n","        #########################################\n","\n","        # Probability of an element getting zeroed\n","        self.dropout = dropout\n","\n","        # Skip classification layer and return node embeddings\n","        self.return_embeds = return_embeds\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","        for bn in self.bns:\n","            bn.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        # TODO: Implement a function that takes the feature tensor x and\n","        # edge_index tensor adj_t and returns the output tensor as\n","        # shown in the figure.\n","\n","        out = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Construct the network as shown in the figure\n","        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch.org/docs/stable/nn.functional.html\n","        ## 3. Don't forget to set F.dropout training to self.training\n","        ## 4. If return_embeds is True, then skip the last softmax layer\n","\n","        #########################################\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"ZNzT46vVIay5"},"source":["## Graph Prediction Model (15 points)\n","\n","Implement a GCN Graph Prediction model using the node embeddings from the GCN model and global pooling to create graph-level embeddings."]},{"cell_type":"markdown","metadata":{"id":"ML9S8EFDKSTK"},"source":["### Graph Mini-Batching\n","Before diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n","\n","The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n","\n","    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n","\n","This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings.\n"]},{"cell_type":"markdown","metadata":{"id":"lyTmlN2eKjOv"},"source":["### Implemention\n","Now, we have all of the tools to implement a GCN Graph Prediction model!  \n","\n","We will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remeber that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJ-kKnhfHwa5"},"outputs":[],"source":["from ogb.graphproppred.mol_encoder import AtomEncoder\n","from torch_geometric.nn import global_add_pool, global_mean_pool\n","\n","### GCN to predict graph property\n","class GCN_Graph(torch.nn.Module):\n","    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n","        super(GCN_Graph, self).__init__()\n","\n","        # Load encoders for Atoms in molecule graphs\n","        self.node_encoder = AtomEncoder(hidden_dim)\n","\n","        # Node embedding model\n","        # Note that the input_dim and output_dim are set to hidden_dim\n","        self.gnn_node = GCN(hidden_dim, hidden_dim,\n","            hidden_dim, num_layers, dropout, return_embeds=True)\n","\n","        self.pool = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Initialize self.pool as a global mean pooling layer\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n","\n","        #########################################\n","\n","        # Output layer\n","        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n","\n","\n","    def reset_parameters(self):\n","      self.gnn_node.reset_parameters()\n","      self.linear.reset_parameters()\n","\n","    def forward(self, batched_data):\n","        # TODO: Implement a function that takes as input a\n","        # mini-batch of graphs (torch_geometric.data.Batch) and\n","        # returns the predicted graph property for each graph.\n","        #\n","        # NOTE: Since we are predicting graph level properties,\n","        # your output will be a tensor with dimension equaling\n","        # the number of graphs in the mini-batch\n","\n","\n","        # Extract important attributes of our mini-batch\n","        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n","        embed = self.node_encoder(x)\n","\n","        out = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Construct node embeddings using existing GCN model\n","        ## 2. Use the global pooling layer to aggregate features for each individual graph\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n","        ## 3. Use a linear layer to predict each graph's property\n","\n","        #########################################\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oach8piLB-f"},"outputs":[],"source":["def train(model, device, data_loader, optimizer, loss_fn):\n","    # TODO: Implement a function that trains your model by\n","    # using the given optimizer and loss_fn.\n","    model.train()\n","    loss = 0\n","\n","    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n","      batch = batch.to(device)\n","\n","      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n","          pass\n","      else:\n","        ## ignore nan targets (unlabeled) when computing training loss.\n","        is_labeled = batch.y == batch.y\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Zero grad the optimizer\n","        ## 2. Feed the data into the model\n","        ## 3. Use `is_labeled` mask to filter output and labels\n","        ## 4. You may need to change the type of label to torch.float32\n","        ## 5. Feed the output and label to the loss_fn\n","        ## (~3 lines of code)\n","\n","        #########################################\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECjb8CqgLCf4"},"outputs":[],"source":["from tqdm import tqdm\n","\n","# The evaluation function\n","def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","\n","    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n","        batch = batch.to(device)\n","\n","        if batch.x.shape[0] == 1:\n","            pass\n","        else:\n","            with torch.no_grad():\n","                pred = model(batch)\n","\n","            y_true.append(batch.y.view(pred.shape).detach().cpu())\n","            y_pred.append(pred.detach().cpu())\n","\n","    y_true = torch.cat(y_true, dim = 0).numpy()\n","    y_pred = torch.cat(y_pred, dim = 0).numpy()\n","\n","    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n","\n","    if save_model_results:\n","        print (\"Saving Model Predictions\")\n","\n","        # Create a pandas dataframe with a two columns\n","        # y_pred | y_true\n","        data = {}\n","        data['y_pred'] = y_pred.reshape(-1)\n","        data['y_true'] = y_true.reshape(-1)\n","\n","        df = pd.DataFrame(data=data)\n","        # Save to csv\n","        df.to_csv('our_graph_' + save_file + '.csv', sep=',', index=False)\n","\n","    return evaluator.eval(input_dict)"]},{"cell_type":"markdown","metadata":{"id":"ZkQAIqkLLulV"},"source":["## Traing and Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBucDYOcPqMM"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwma05T3MLYH"},"outputs":[],"source":["args = {'device': device, 'num_layers': 5, 'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'epochs': 30}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4wq--aAQas-"},"outputs":[],"source":["evaluator = None\n","dataset = None\n","\n","# Ex. DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n","train_loader = None\n","test_loader = None\n","val_loader = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jv9xwDEyLE_6"},"outputs":[],"source":["model = GCN_Graph(\n","    args['hidden_dim'], dataset.num_tasks, args['num_layers'], args['dropout']).to(device)\n","\n","model.reset_parameters()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n","loss_fn = torch.nn.BCEWithLogitsLoss()\n","\n","best_model = None\n","best_valid_acc = 0\n","\n","for epoch in range(1, 1 + args[\"epochs\"]):\n","\n","    print('Training...')\n","    loss = train(model, device, train_loader, optimizer, loss_fn)\n","\n","    print('Evaluating...')\n","    train_result = eval(model, device, train_loader, evaluator)\n","    val_result = eval(model, device, val_loader, evaluator)\n","    test_result = eval(model, device, test_loader, evaluator)\n","\n","    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n","    if valid_acc > best_valid_acc:\n","        best_valid_acc = valid_acc\n","        best_model = copy.deepcopy(model)\n","\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {100 * train_acc:.2f}%, Valid: {100 * valid_acc:.2f}% Test: {100 * test_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"LpQcX7DMMoXV"},"source":["## Other Experiments (5 points)\n","\n","Experiment with different global pooling layers in PyTorch Geometric and observe the changes in model performance. [Two global pooling layers other than mean pooling in Pytorch Geometric.]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33KD9Mv8MsQi"},"outputs":[],"source":["# Experiment_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBn3xndLMta-"},"outputs":[],"source":["# Experiment_2"]},{"cell_type":"markdown","metadata":{"id":"XrRM5XLbVA7f"},"source":["Important Reminder: The functions provided in this notebook serve as initial templates and examples. You are encouraged to modify and adapt them as needed to suit your specific requirements or to improve performance. However, while making these changes, please endeavor to preserve the overall structure and objectives of the exercise.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
